{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from flask import Flask\n",
    "# app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymongo\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "###twitter\n",
    "import json\n",
    "import tweepy \n",
    "import scrapy\n",
    "import sys\n",
    "sys.path.append('/Users/jyj/Dropbox/A_A_Data_Analysis/Group_Projects')\n",
    "# Import Twitter API Keys\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/chromedriver\r\n"
     ]
    }
   ],
   "source": [
    "# https://splinter.readthedocs.io/en/latest/drivers/chrome.html\n",
    "!which chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "# browser = Browser('chrome', **executable_path, headless=False)\n",
    "# browser = Browser('django')\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "url=\"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestSpider(scrapy.Spider):\n",
    "    name = \"test\"\n",
    "\n",
    "    start_urls = [\n",
    "        \"http://stackoverflow.com/questions/38233614/download-a-full-page-with-scrapy\",\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        filename = response.url.split(\"/\")[-1] + '.html'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile example.py\n",
    "import scrapy\n",
    "class TestSpider(scrapy.Spider):\n",
    "    name = \"test\"\n",
    "\n",
    "    start_urls = [\n",
    "    \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    ",\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        filename = response.url.split(\"/\")[-1] + '.html'\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-12-15 01:41:38 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: scrapybot)\n",
      "2018-12-15 01:41:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.7 |Anaconda, Inc.| (default, Oct 23 2018, 14:01:38) - [GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0j  20 Nov 2018), cryptography 2.4.2, Platform Darwin-17.7.0-x86_64-i386-64bit\n",
      "2018-12-15 01:41:38 [scrapy.crawler] INFO: Overridden settings: {'SPIDER_LOADER_WARN_ONLY': True}\n",
      "2018-12-15 01:41:38 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2018-12-15 01:41:38 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2018-12-15 01:41:38 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2018-12-15 01:41:38 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2018-12-15 01:41:38 [scrapy.core.engine] INFO: Spider opened\n",
      "2018-12-15 01:41:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2018-12-15 01:41:38 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023\n",
      "2018-12-15 01:41:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest> (referer: None)\n",
      "2018-12-15 01:41:39 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2018-12-15 01:41:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 335,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 12934,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2018, 12, 15, 7, 41, 39, 234569),\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 7,\n",
      " 'memusage/max': 50954240,\n",
      " 'memusage/startup': 50954240,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2018, 12, 15, 7, 41, 38, 759410)}\n",
      "2018-12-15 01:41:39 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "scrapy runspider example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-715ab272e45d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mlatest_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.content_title a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mlatest_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.article_teaser_body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mlatest_title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#NASA Mars latest News: this code block will generate latest_news\n",
    "url0=\"https://mars.nasa.gov/news/\"\n",
    "url=\"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "\n",
    "# executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "# browser = Browser('chrome', **executable_path, headless=False)\n",
    "# browser.visit(url)\n",
    "# html = browser.html\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "response = requests.get(url)\n",
    "# Create BeautifulSoup object; parse with 'lxml'\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "results = soup.select('.list_text')\n",
    "\n",
    "results\n",
    "\n",
    "latest_title=results[0].select('.content_title a')[0].get_text()\n",
    "latest_text=results[0].select('.article_teaser_body')[0].get_text()\n",
    "latest_title\n",
    "latest_text\n",
    "latest_news={\"title\":latest_title,\"text\":latest_text}\n",
    "# i=0;\n",
    "# for result in results:\n",
    "#         i+=1\n",
    "#         print(i,'. ','title=',result.select('h3')[0].get_text());\n",
    "#         print(i,'. ', 'text=',result.select('div.article_teaser_body')[0].get_text());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = soup.select('.grid_layout')\n",
    "len(results)\n",
    "# results=soup.find_all(\"ul\", class_=\"item_list \")\n",
    "# # len(results[0].select(\"li\"))\n",
    "# len(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"NASA's Mars InSight Flexes Its Arm\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\"Now unstowed, the spacecraft's robotic arm will point a camera located on its elbow and take images of the surroundings.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = soup.select('.list_text')\n",
    "\n",
    "len(results)\n",
    "\n",
    "latest_title=results[0].select('.content_title a')[0].get_text()\n",
    "latest_text=results[0].select('.article_teaser_body')[0].get_text()\n",
    "latest_title\n",
    "latest_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#JPL Mars Space Images - Featured Image: this code block will generate featured_image_url\n",
    "Mars_Space_Images=\"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\";\n",
    "browser.visit(Mars_Space_Images)\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "results = soup.select('div.carousel_items')\n",
    "# results[0].select('article')[0][\"style\"]\n",
    "RE=re.compile(r\"'/.*.jpg'\")\n",
    "featured_image_url='https://www.jpl.nasa.gov'+RE.findall(results[0].select('article')[0][\"style\"])[0].strip(\"'\")\n",
    "featured_image_url\n",
    "browser.visit(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa=results[0].select('article')[0][\"style\"]\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa\n",
    "aa.lstrip(\"'background-image: url(\").rstrip('''');\"''')\n",
    "\n",
    "aa          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mars Weather: this code block will get latest mars_weather mars_weather from twitter\n",
    "#method 1: web scraping \n",
    "weather_url='https://twitter.com/marswxreport?lang=en'\n",
    "response = requests.get(weather_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "mars_weather = soup.select(\"li.js-stream-item\")[0].select(\"p.TweetTextSize\")[0].text\n",
    "mars_weather\n",
    "# method2: get results by twitter api:\n",
    "public_tweets = api.user_timeline(\"@MarsWxReport\")\n",
    "public_tweets[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facts_dict_keys.pop()\n",
    "facts_dict_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(facts_dict.keys())\n",
    "facts_dict_keys=list(facts_dict.keys())\n",
    "facts_dict_values=list(facts_dict.values())\n",
    "facts_dict_keys.pop()\n",
    "facts_dict_values.pop()\n",
    "facts_dict_keys\n",
    "facts_dict_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mars Facts: this code block will get some facts (written in facts_dict/facts_df/facts_html)\n",
    "#about MAR\n",
    "facts_url=\"https://space-facts.com/mars/\"\n",
    "response = requests.get(facts_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# len(soup.select(\"table\"))\n",
    "col1=[a.get_text() for a in soup.select(\"table\")[0].select(\".column-1\")]\n",
    "col1=[a.rstrip('[:]') for a in col1]\n",
    "col2=[a.get_text() for a in soup.select(\"table\")[0].select(\".column-2\")]\n",
    "col2=[a.rstrip('\\n') for a in col2]\n",
    "facts_dict = dict(zip(col1,col2))\n",
    "facts_dict\n",
    "\n",
    "#######\n",
    "tables = pd.read_html(facts_url)\n",
    "facts_df=tables[0].rename(columns={0:\" \",1:\"Value\"}).set_index(\" \")\n",
    "facts_df\n",
    "facts_html= facts_df.to_html()\n",
    "facts_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mars Hemispheres: this block code generate titles and url's for hemisphere images for MAr\n",
    "#which are included in a list of dicts hemisphere_image_urls:\n",
    "Hemispheres_url=\"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "response = requests.get(Hemispheres_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "title=[]\n",
    "img_url=[]\n",
    "for item in  soup.select('a.itemLink'):\n",
    "    title.append(item.select('h3')[0].get_text())\n",
    "    url_enhanced=\"https://astrogeology.usgs.gov\"+item[\"href\"]\n",
    "    response1 = requests.get(url_enhanced)\n",
    "    soup1 = BeautifulSoup(response1.text, 'html.parser')\n",
    "    img_url.append(\"https://astrogeology.usgs.gov\"+soup1.select('img.wide-image')[0]['src'])\n",
    "    \n",
    "hemisphere_image_urls = [{'title':title[i],'img_url':img_url[i]} for i in range(len(title))]\n",
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we put all the data into Mongo:\n",
    "\n",
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "# Define database and collection\n",
    "client.drop_database('Mars_db')\n",
    "\n",
    "db = client.Mars_db\n",
    "\n",
    "\n",
    "collection = db.Mars_hemisphere_image_urls\n",
    "collection.drop()\n",
    "collection.insert_many(hemisphere_image_urls)\n",
    "results=collection.find()\n",
    "results=[result for result in results]\n",
    "results\n",
    "    \n",
    "collection = db.Mars_facts_dict\n",
    "collection.drop()\n",
    "collection.insert_one(facts_dict)\n",
    "results=collection.find()\n",
    "results[0]\n",
    "\n",
    "collection = db.Mars_weather\n",
    "collection.drop()\n",
    "collection.insert_one({\"mars_weather\":mars_weather})\n",
    "results=collection.find()\n",
    "results[0]\n",
    "\n",
    "collection = db.Mars_latest_news\n",
    "collection.drop()\n",
    "collection.insert_one(latest_news)\n",
    "results=collection.find()\n",
    "results[0]\n",
    "\n",
    "collection = db.Mars_featured_image_url\n",
    "collection.drop()\n",
    "collection.insert_one({\"featured_image_url\":featured_image_url})\n",
    "results=collection.find()\n",
    "results[0]\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collection = db.Mars_featured_image_url\n",
    "collection.drop()\n",
    "collection.insert_one({\"featured_image_url\":featured_image_url})\n",
    "results=collection.find()\n",
    "results[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mars_data={\"hemisphere_image_urls\":hemisphere_image_urls,\"facts_df\":facts_dict,\\\n",
    "           \"mars_weather\":mars_weather,\"latest_news\":latest_news,\"featured_image_url\":featured_image_url}\n",
    "\n",
    "\n",
    "\n",
    "Mars_data={\"hemisphere_image_urls\":hemisphere_image_urls,\"facts_df\":facts_dict,\\\n",
    "           \"mars_weather\":mars_weather,\"latest_news\":latest_news,\"featured_image_url\":featured_image_url}\n",
    "\n",
    "\n",
    "#Mars_data=[{key:value} for key,value in Mars_data]\n",
    "dictlist=[]\n",
    "for key, value in Mars_data.items():\n",
    "    type(key)\n",
    "    type(value)\n",
    "    value\n",
    "    temp = value[0]\n",
    "#     temp\n",
    "#     break\n",
    "    dictlist.append(temp)\n",
    "Mars_data=dictlist\n",
    "\n",
    "type(Mars_data)\n",
    "\n",
    "\n",
    "collection.insertMany(Mars_data)\n",
    "\n",
    "# client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings =[]\n",
    "listings = db.Mars.find()\n",
    "\n",
    "for listing in listings:\n",
    "    print(listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, redirect\n",
    "from flask_pymongo import PyMongo\n",
    "from scrapy_mars import scrape\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config[\"MONGO_URI\"] = \"mongodb://localhost:27017/Mars_db\"\n",
    "mongo = PyMongo(app)\n",
    "\n",
    "mongo.db.drop_collection (\"Mars_hemisphere_image_urls\")\n",
    "hemisphere_image_urls=mongo.db.Mars_hemisphere_image_urls.find()\n",
    "hemisphere_image_urls=[result for result in hemisphere_image_urls]\n",
    "hemisphere_image_urls\n",
    "\n",
    "\n",
    "Mars_facts_dict=mongo.db.Mars_facts_dict.find()\n",
    "Mars_facts_dict[0]\n",
    "\n",
    "Mars_weather=mongo.db.Mars_weather.find()\n",
    "Mars_weather[0]\n",
    "\n",
    "Mars_latest_news=mongo.db.Mars_latest_news.find()\n",
    "Mars_latest_news[0]\n",
    "\n",
    "Mars_featured_image_url=mongo.db. Mars_featured_image_url.find()\n",
    "Mars_featured_image_url[0]\n",
    "\n",
    "#  Mars_hemisphere_image_urls\n",
    "#     Mars_facts_dict\n",
    "#     Mars_weather\n",
    "#     Mars_latest_news\n",
    "#     Mars_featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# listings = mongo.db.Mars.find_one()\n",
    "# listings\n",
    "mongo.db.dropDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listings = mongo.db.listings\n",
    "listings_data = {'A':2,'B':3}\n",
    "listings.update({}, listings_data, upsert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mongo.db.watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"https://astrogeology.usgs.gov\"+\"/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg\"\n",
    "# \"https://astrogeology.usgs.gov\"+\"/cache/images/dfaf3849e74bf973b59eb50dab52b583_cerberus_enhanced.tif_thumb.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import scrapy\n",
    "\n",
    "\n",
    "# class MofanSpider(scrapy.Spider):\n",
    "#     name = \"James\"\n",
    "#     start_urls = [\n",
    "#       \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "\n",
    "#     ]\n",
    "#     # unseen = set()\n",
    "#     # seen = set()      # we don't need these two as scrapy will deal with them automatically\n",
    "\n",
    "#     def parse(self, response):\n",
    "#         yield {     # return some results\n",
    "#             'title': response.css('h1::text').extract_first(default='Missing').strip().replace('\"', \"\"),\n",
    "#             'url': response.url,\n",
    "#         }\n",
    "\n",
    "#         urls = response.css('a::attr(href)').re(r'^/.+?/$')     # find all sub urls\n",
    "#         for url in urls:\n",
    "#             yield response.follow(url, callback=self.parse)     # it will filter duplication automatically\n",
    "\n",
    "\n",
    "# # lastly, run this in terminal\n",
    "# # scrapy runspider 5-2-scrapy.py -o res.json\n",
    "# %%bash\n",
    "# scrapy runspider James_scrapy.py -o res.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Step 2 - MongoDB and Flask Application\n",
    "\n",
    " \n",
    " <h4 class=\"heading\">{{(listings[\"latest_news\"])[\"title\"]}}</h4>\n",
    "        \n",
    "          <small>{{listings['featured_image_url']}}</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mars_data={\"hemisphere_image_urls\":hemisphere_image_urls,\"facts_df\":facts_dict,\\\n",
    "           \"mars_weather\":mars_weather,\"latest_news\":latest_news,\"featured_image_url\":featured_image_url}\n",
    "\n",
    "\n",
    "#Mars_data=[{key:value} for key,value in Mars_data]\n",
    "dictlist=[]\n",
    "for key, value in Mars_data.items():\n",
    "    type(key)\n",
    "    type(value)\n",
    "    value\n",
    "    temp = value[0]\n",
    "#     temp\n",
    "#     break\n",
    "    dictlist.append(temp)\n",
    "Mars_data=dictlist\n",
    "\n",
    "type(Mars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Mars_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
